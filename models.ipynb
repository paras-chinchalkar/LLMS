{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38dc37d6a56c4b9d9474cc68412f5199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0b411fac436470a90d7287c36f7bd49",
              "IPY_MODEL_f9043496ce1c4a9b881c1a58e010b79c",
              "IPY_MODEL_f1975452be634556a900734786907c68"
            ],
            "layout": "IPY_MODEL_24432c52f54a4014bfd50177351eb721"
          }
        },
        "c0b411fac436470a90d7287c36f7bd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28b961df63f544cc9a7054ae79b29bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_92ce421002de42f3afdf84609bd20293",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f9043496ce1c4a9b881c1a58e010b79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44bc18194d64a54af8d09a7d97d03fd",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb268229657f4ffc85c23936a0d5f763",
            "value": 4
          }
        },
        "f1975452be634556a900734786907c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0828d2d7b384656941354856e876626",
            "placeholder": "​",
            "style": "IPY_MODEL_cabd142e36a348a6acbdf6ec9cebf4b0",
            "value": " 4/4 [00:36&lt;00:00,  7.91s/it]"
          }
        },
        "24432c52f54a4014bfd50177351eb721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b961df63f544cc9a7054ae79b29bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ce421002de42f3afdf84609bd20293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d44bc18194d64a54af8d09a7d97d03fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb268229657f4ffc85c23936a0d5f763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0828d2d7b384656941354856e876626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabd142e36a348a6acbdf6ec9cebf4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate"
      ],
      "metadata": {
        "id": "H2BoxE1RTa7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CYiRzOxsKpOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer, BitsAndBytesConfig\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "wJOvJekxTp7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token=userdata.get(\"project\")"
      ],
      "metadata": {
        "id": "1Dcr7EgwT48f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(hf_token,add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "GFo47nRLpOml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLAMA=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "PHI3=\"microsoft/Phi-3-mini-4k-instruct\"\n",
        "GEMMA2=\"google/gemma-2-2b-it\"\n",
        "QUEN2=\"Qwen/Qwen2.5-7B-Instruct\"\n",
        "MIXTRAL=\"mistralai/Mixtral-8x7B-Instruct-v0.1\""
      ],
      "metadata": {
        "id": "t_UcQA5kpWYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\":\"system\",\"content\":\"You ar  a helpful assistant\"},\n",
        "    {\"role\":\"user\",\"content\":\"What is the meaning of life?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "Fnld_YNj1trR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qunatization configuration-this allows us to load the model into memory and use less memory\n",
        "#tHIS THING IS REALLY USEFUL AT MANY PLACES\n",
        "quant_config=BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "Rkts3ENj2YmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token=tokenizer.eos_token#Okten used to fill up the prompt of ours\n",
        "inputs=tokenizer.apply_chat_template(messages,return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "MoLMTtbG2vl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbMqcG9kL3Zu",
        "outputId": "9ff82cd6-aa91-427b-860d-e58905d40a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cpu)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the model\n",
        "model=AutoModelForCausalLM.from_pretrained(LLAMA,device_map=\"auto\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "38dc37d6a56c4b9d9474cc68412f5199",
            "c0b411fac436470a90d7287c36f7bd49",
            "f9043496ce1c4a9b881c1a58e010b79c",
            "f1975452be634556a900734786907c68",
            "24432c52f54a4014bfd50177351eb721",
            "28b961df63f544cc9a7054ae79b29bc6",
            "92ce421002de42f3afdf84609bd20293",
            "d44bc18194d64a54af8d09a7d97d03fd",
            "bb268229657f4ffc85c23936a0d5f763",
            "a0828d2d7b384656941354856e876626",
            "cabd142e36a348a6acbdf6ec9cebf4b0"
          ]
        },
        "id": "h-RaVIRN3dES",
        "outputId": "90dc35cb-3560-4e2b-bddf-34432b8d3ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38dc37d6a56c4b9d9474cc68412f5199"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory=model.get_memory_footprint()/1e6"
      ],
      "metadata": {
        "id": "y9mMgUb94KX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hN8I8RuqMPVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Memory footprint fo the model is {memory} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80oLstX08mT8",
        "outputId": "eab5f893-69ae-4286-ada6-2dc3431266b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory footprint fo the model is 32121.045248 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model #Actual deep neural netrok fo  our model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooxo6mi38wHH",
        "outputId": "2f3b216b-1cc6-4e8b-848f-99b1bdd1682d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
        "model.to(device)\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(inputs, max_new_tokens=80)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zszu-Kn89a9J",
        "outputId": "6e65c687-7088-4dd7-8d1c-977347826ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages1=[\n",
        "    {\"role\":\"system\",\"content\":\"Hi assisant\"},\n",
        "    {\"role\":\"user\",\"content\":\"tell me a joke?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "S3EUuhO69xi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(messages1, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(inputs, max_new_tokens=80)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "id": "A7oZ7kty-U9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in ['inputs', 'outputs', 'model']:\n",
        "    if var in locals():\n",
        "        del globals()[var]\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "25lKyb50-XGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wrapping everything  in a function and adding Streamling\n",
        "def generate(model,messages):\n",
        "    tokenizer=AutoTokenizer.from_pretrained(LLAMA)\n",
        "    tokenizer.pad_token=tokenizer.eos_token\n",
        "    model=AutoModelForCausalLM.from_pretrained(LLAMA,quantization_config=quant_config,device_map=\"auto\")\n",
        "    inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "    outputs=model.generate(input ,max_new_tokens=80,streamer=streamer)\n",
        "    del tokenizer,streamer,model,inputs,outputs\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LtG4tSc2_el9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(PHI3,messages)"
      ],
      "metadata": {
        "id": "kBUlYR1VATc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhMsZO1aAlOv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}